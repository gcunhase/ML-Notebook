{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rnn_tensorflow.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gcunhase/ML-Notebook/blob/master/rnn_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "komM0p7jHNWf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Recurrent Neural Network"
      ]
    },
    {
      "metadata": {
        "id": "8QjsOJ8uHS27",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. Libraries\n",
        "*Installing and importing necessary packages*\n",
        "\n",
        "*Working with **Python3** and  **TensorFlow 1.13.0-rc1***"
      ]
    },
    {
      "metadata": {
        "id": "BwCoRr4IHYeb",
        "colab_type": "code",
        "outputId": "d0d476ac-050d-4469-b06e-eb4302e672e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n",
        "import tensorflow as tf\n",
        "print(\"Tensorflow version: {}\".format(tf.__version__))\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "from tensorflow.contrib import rnn\n",
        "from tensorflow.nn.rnn_cell import LSTMCell\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from timeit import default_timer as timer "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (1.13.0rc1)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.14.6)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.32.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.9)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.6.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.13.0rc0)\n",
            "Requirement already satisfied: tensorboard<1.13.0,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow) (40.8.0)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0rc0->tensorflow) (2.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow) (2.8.0)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python3.6/dist-packages (from mock>=2.0.0->tensorflow-estimator<1.14.0rc0,>=1.13.0rc0->tensorflow) (5.1.2)\n",
            "Tensorflow version: 1.13.0-rc1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8dc9zFg73RZ-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*List available devices*"
      ]
    },
    {
      "metadata": {
        "id": "gDTfbjcSs8uG",
        "colab_type": "code",
        "outputId": "5372aa64-159c-45e8-b94d-bb9d767b964e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 7147947743928510523\n",
            ", name: \"/device:XLA_CPU:0\"\n",
            "device_type: \"XLA_CPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 15870546044854760824\n",
            "physical_device_desc: \"device: XLA_CPU device\"\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Lq_7RUzDFU20",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. Dataset\n",
        "*Data is split in 3 parts* : `mnist.train` (55,000 images), `mnist.test` (10,000 images), and `mnist.validation` (5,000 images)"
      ]
    },
    {
      "metadata": {
        "id": "mMXS2_PQFbXN",
        "colab_type": "code",
        "outputId": "55d2a1c2-37d6-4220-b914-8cc2159d368f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        }
      },
      "cell_type": "code",
      "source": [
        "mnist = input_data.read_data_sets(\"./data/\", one_hot=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-4-f659c5e1ce47>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting ./data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting ./data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting ./data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting ./data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xflZKkSMHc1E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3. Variables\n",
        "*Indicate the root directory where the data must be downloaded, the directory where the results should be saved and the type of RNN (conventional, LSTM, GRU) and its respective hyper-parameters*"
      ]
    },
    {
      "metadata": {
        "id": "YxhT6SpBSt46",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Constants"
      ]
    },
    {
      "metadata": {
        "id": "vVBfSALMSWcv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define constants\n",
        "params = {\n",
        "  'num_hidden_units': 128,  # hidden layer\n",
        "  'n_input': 28,  # MNIST data input (img shape: 28*28)\n",
        "  'time_steps': 28,\n",
        "  'lr': 0.001,\n",
        "  'n_classes': 10,  # class 0-9\n",
        "  'batch_size': 128,\n",
        "  'cell_type': 'LSTM',  # Options = [RNN, LSTM, GRU]\n",
        "  'step': 100000,\n",
        "  'display_step': 200\n",
        "}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bK3ZheVcSw3c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Placeholders"
      ]
    },
    {
      "metadata": {
        "id": "slwSHJ7oSz8I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Weights and biases\n",
        "out_weights = tf.Variable(tf.random_normal([params['num_hidden_units'], params['n_classes']]))\n",
        "out_bias = tf.Variable(tf.random_normal([params['n_classes']]))\n",
        "\n",
        "# Placeholders: input image and label\n",
        "x = tf.placeholder(\"float\",[None, params['time_steps'], params['n_input']])\n",
        "y = tf.placeholder(\"float\",[None, params['n_classes']])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZsrN6fDkHowX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 4. The Model: RNN"
      ]
    },
    {
      "metadata": {
        "id": "EqifJVXSJFbq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Defining model"
      ]
    },
    {
      "metadata": {
        "id": "UOA8oetNFipZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def RNN(x, w, b, cell_type='RNN'):\n",
        "  # Get a list of 'timesteps' tensors of shape (bs, n_input=28)\n",
        "  x_timesteps = tf.unstack(x, params['time_steps'], 1)\n",
        "  \n",
        "  # Cell definition\n",
        "  if cell_type == 'RNN':\n",
        "    rnn_layer = tf.keras.layers.SimpleRNNCell(params['num_hidden_units'])\n",
        "    # Deprecated: rnn_layer = rnn.BasicRNNCell(params['num_hidden_units'])\n",
        "  elif cell_type == 'LSTM':\n",
        "    rnn_layer = tf.keras.layers.LSTMCell(params['num_hidden_units'], unit_forget_bias=True)  # rnn.BasicLSTMCell(params['num_hidden_units'], forget_bias=1.0)\n",
        "  elif cell_type == 'GRU':\n",
        "    rnn_layer = tf.keras.layers.GRUCell(params['num_hidden_units'])  # rnn.GRUCell(params['num_hidden_units'])\n",
        "  \n",
        "  # Cell output\n",
        "  out, h = rnn.static_rnn(rnn_layer, x_timesteps, dtype=tf.float32)\n",
        "\n",
        "  # Linear activation with the last output + softmax\n",
        "  pred = tf.nn.softmax(tf.matmul(out[-1], w) + b)\n",
        "  return pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OFpv2PTOJIFy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Instantiating model"
      ]
    },
    {
      "metadata": {
        "id": "ds4X2AbOJJ-6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "prediction = RNN(x, out_weights, out_bias, cell_type=params['cell_type'])\n",
        "\n",
        "# Loss: cross-entropy\n",
        "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=prediction, labels=y))\n",
        "\n",
        "# Optimizer: gradient descent\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=params['lr'])\n",
        "train_op = optimizer.minimize(loss_op)\n",
        "\n",
        "# Evaluate model (with test logits, for dropout to be disabled)\n",
        "pred = tf.argmax(prediction, 1)\n",
        "tar = tf.argmax(y, 1)\n",
        "correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vi6B8vuiHrJv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 5. Train\n",
        "*Start session and run*"
      ]
    },
    {
      "metadata": {
        "id": "EAH9Y8ezNCbM",
        "colab_type": "code",
        "outputId": "b8954983-0da6-48b5-a336-c64d4e8b3981",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 9412
        }
      },
      "cell_type": "code",
      "source": [
        "start_timer = timer()\n",
        "\n",
        "# To use gpu\n",
        "#if params['use_gpu'] == True:\n",
        "#  config = tf.ConfigProto(log_device_placement=True)\n",
        "#  sess = tf.Session(config=config)\n",
        "\n",
        "# Make global session to use in test later\n",
        "#  otherwise create local session with 'with tf.Session() as sess:\n",
        "sess = tf.Session()\n",
        "\n",
        "# Run initializer: initializes variables with their assigned values\n",
        "init = tf.global_variables_initializer()\n",
        "sess.run(init)\n",
        "\n",
        "loss_arr = []\n",
        "step_arr = []\n",
        "train_arr = []\n",
        "for step in range(1, params['step']+1):\n",
        "    # Next batch returns (bs, 28*28)\n",
        "    batch_x, batch_y = mnist.train.next_batch(batch_size=params['batch_size'])\n",
        "        \n",
        "    # Reshape data to (bs, 28, 28)\n",
        "    batch_x = batch_x.reshape((params['batch_size'], params['time_steps'], params['n_input']))\n",
        "        \n",
        "    # Backpropagation: run train_op variable\n",
        "    sess.run(train_op, feed_dict={x: batch_x, y: batch_y})\n",
        "        \n",
        "    # Calculate batch loss (loss_op) and accuracy\n",
        "    if step % params['display_step'] == 0 or step == 1:\n",
        "        loss, acc = sess.run([loss_op, accuracy], feed_dict={x: batch_x, y: batch_y})\n",
        "        loss_arr.append(loss)\n",
        "        step_arr.append(step)\n",
        "        train_arr.append(acc)\n",
        "        print(\"Step {}, Minibatch loss {:.4f}, Train acc {:.4f}, Best train acc {:.4f}\".format(step, loss, acc, max(train_arr)))\n",
        "        \n",
        "# Plot training loss curve\n",
        "plt.plot(step_arr, loss_arr)\n",
        "plt.title('Training loss curve')\n",
        "plt.xlabel('Step')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()\n",
        "\n",
        "end_timer = timer() - start_timer\n",
        "\n",
        "print(\"Model took {:.4f} mins ({:.4f} hrs) to finish training with best train accuracy of {:.4f}%\".format(end_timer/60, end_timer/3600, max(train_arr)*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 1, Minibatch loss 2.2996, Train acc 0.1328, Best train acc 0.1328\n",
            "Step 200, Minibatch loss 2.3160, Train acc 0.0703, Best train acc 0.1328\n",
            "Step 400, Minibatch loss 2.3042, Train acc 0.1094, Best train acc 0.1328\n",
            "Step 600, Minibatch loss 2.3065, Train acc 0.1094, Best train acc 0.1328\n",
            "Step 800, Minibatch loss 2.3037, Train acc 0.1172, Best train acc 0.1328\n",
            "Step 1000, Minibatch loss 2.2950, Train acc 0.1797, Best train acc 0.1797\n",
            "Step 1200, Minibatch loss 2.2826, Train acc 0.1641, Best train acc 0.1797\n",
            "Step 1400, Minibatch loss 2.2644, Train acc 0.2344, Best train acc 0.2344\n",
            "Step 1600, Minibatch loss 2.2720, Train acc 0.1953, Best train acc 0.2344\n",
            "Step 1800, Minibatch loss 2.2712, Train acc 0.1875, Best train acc 0.2344\n",
            "Step 2000, Minibatch loss 2.2745, Train acc 0.1641, Best train acc 0.2344\n",
            "Step 2200, Minibatch loss 2.2441, Train acc 0.2188, Best train acc 0.2344\n",
            "Step 2400, Minibatch loss 2.2298, Train acc 0.2266, Best train acc 0.2344\n",
            "Step 2600, Minibatch loss 2.2255, Train acc 0.2344, Best train acc 0.2344\n",
            "Step 2800, Minibatch loss 2.2191, Train acc 0.2422, Best train acc 0.2422\n",
            "Step 3000, Minibatch loss 2.2323, Train acc 0.2266, Best train acc 0.2422\n",
            "Step 3200, Minibatch loss 2.2033, Train acc 0.2344, Best train acc 0.2422\n",
            "Step 3400, Minibatch loss 2.1649, Train acc 0.3047, Best train acc 0.3047\n",
            "Step 3600, Minibatch loss 2.1482, Train acc 0.3281, Best train acc 0.3281\n",
            "Step 3800, Minibatch loss 2.1464, Train acc 0.3203, Best train acc 0.3281\n",
            "Step 4000, Minibatch loss 2.2225, Train acc 0.2031, Best train acc 0.3281\n",
            "Step 4200, Minibatch loss 2.1956, Train acc 0.2500, Best train acc 0.3281\n",
            "Step 4400, Minibatch loss 2.1754, Train acc 0.2812, Best train acc 0.3281\n",
            "Step 4600, Minibatch loss 2.1975, Train acc 0.2266, Best train acc 0.3281\n",
            "Step 4800, Minibatch loss 2.1340, Train acc 0.3594, Best train acc 0.3594\n",
            "Step 5000, Minibatch loss 2.2004, Train acc 0.2422, Best train acc 0.3594\n",
            "Step 5200, Minibatch loss 2.1394, Train acc 0.3438, Best train acc 0.3594\n",
            "Step 5400, Minibatch loss 2.1397, Train acc 0.3516, Best train acc 0.3594\n",
            "Step 5600, Minibatch loss 2.1842, Train acc 0.2891, Best train acc 0.3594\n",
            "Step 5800, Minibatch loss 2.1566, Train acc 0.3281, Best train acc 0.3594\n",
            "Step 6000, Minibatch loss 2.1503, Train acc 0.3359, Best train acc 0.3594\n",
            "Step 6200, Minibatch loss 2.1128, Train acc 0.3672, Best train acc 0.3672\n",
            "Step 6400, Minibatch loss 2.1288, Train acc 0.3750, Best train acc 0.3750\n",
            "Step 6600, Minibatch loss 2.1458, Train acc 0.3359, Best train acc 0.3750\n",
            "Step 6800, Minibatch loss 2.1287, Train acc 0.3984, Best train acc 0.3984\n",
            "Step 7000, Minibatch loss 2.1544, Train acc 0.3125, Best train acc 0.3984\n",
            "Step 7200, Minibatch loss 2.1907, Train acc 0.2812, Best train acc 0.3984\n",
            "Step 7400, Minibatch loss 2.1157, Train acc 0.3672, Best train acc 0.3984\n",
            "Step 7600, Minibatch loss 2.1130, Train acc 0.3828, Best train acc 0.3984\n",
            "Step 7800, Minibatch loss 2.1438, Train acc 0.3359, Best train acc 0.3984\n",
            "Step 8000, Minibatch loss 2.0839, Train acc 0.4141, Best train acc 0.4141\n",
            "Step 8200, Minibatch loss 2.0717, Train acc 0.4453, Best train acc 0.4453\n",
            "Step 8400, Minibatch loss 2.0860, Train acc 0.4219, Best train acc 0.4453\n",
            "Step 8600, Minibatch loss 2.0706, Train acc 0.4531, Best train acc 0.4531\n",
            "Step 8800, Minibatch loss 2.1214, Train acc 0.3828, Best train acc 0.4531\n",
            "Step 9000, Minibatch loss 2.0781, Train acc 0.4219, Best train acc 0.4531\n",
            "Step 9200, Minibatch loss 2.1345, Train acc 0.3438, Best train acc 0.4531\n",
            "Step 9400, Minibatch loss 2.0378, Train acc 0.4609, Best train acc 0.4609\n",
            "Step 9600, Minibatch loss 2.1331, Train acc 0.3516, Best train acc 0.4609\n",
            "Step 9800, Minibatch loss 2.1184, Train acc 0.3594, Best train acc 0.4609\n",
            "Step 10000, Minibatch loss 2.1131, Train acc 0.3828, Best train acc 0.4609\n",
            "Step 10200, Minibatch loss 2.1323, Train acc 0.3516, Best train acc 0.4609\n",
            "Step 10400, Minibatch loss 2.0829, Train acc 0.3828, Best train acc 0.4609\n",
            "Step 10600, Minibatch loss 2.1210, Train acc 0.3594, Best train acc 0.4609\n",
            "Step 10800, Minibatch loss 2.0777, Train acc 0.4219, Best train acc 0.4609\n",
            "Step 11000, Minibatch loss 2.0738, Train acc 0.4062, Best train acc 0.4609\n",
            "Step 11200, Minibatch loss 2.0455, Train acc 0.4453, Best train acc 0.4609\n",
            "Step 11400, Minibatch loss 2.0827, Train acc 0.3906, Best train acc 0.4609\n",
            "Step 11600, Minibatch loss 2.1067, Train acc 0.3438, Best train acc 0.4609\n",
            "Step 11800, Minibatch loss 2.0984, Train acc 0.3828, Best train acc 0.4609\n",
            "Step 12000, Minibatch loss 2.0792, Train acc 0.4141, Best train acc 0.4609\n",
            "Step 12200, Minibatch loss 2.0881, Train acc 0.3750, Best train acc 0.4609\n",
            "Step 12400, Minibatch loss 2.0144, Train acc 0.4922, Best train acc 0.4922\n",
            "Step 12600, Minibatch loss 2.0552, Train acc 0.4219, Best train acc 0.4922\n",
            "Step 12800, Minibatch loss 2.0982, Train acc 0.3594, Best train acc 0.4922\n",
            "Step 13000, Minibatch loss 2.0588, Train acc 0.4219, Best train acc 0.4922\n",
            "Step 13200, Minibatch loss 2.0655, Train acc 0.4219, Best train acc 0.4922\n",
            "Step 13400, Minibatch loss 2.0587, Train acc 0.4297, Best train acc 0.4922\n",
            "Step 13600, Minibatch loss 2.0605, Train acc 0.4062, Best train acc 0.4922\n",
            "Step 13800, Minibatch loss 2.0116, Train acc 0.4844, Best train acc 0.4922\n",
            "Step 14000, Minibatch loss 2.0789, Train acc 0.3984, Best train acc 0.4922\n",
            "Step 14200, Minibatch loss 2.0322, Train acc 0.4688, Best train acc 0.4922\n",
            "Step 14400, Minibatch loss 2.0782, Train acc 0.4062, Best train acc 0.4922\n",
            "Step 14600, Minibatch loss 2.0272, Train acc 0.4609, Best train acc 0.4922\n",
            "Step 14800, Minibatch loss 2.0109, Train acc 0.4766, Best train acc 0.4922\n",
            "Step 15000, Minibatch loss 2.1053, Train acc 0.3516, Best train acc 0.4922\n",
            "Step 15200, Minibatch loss 2.0418, Train acc 0.4297, Best train acc 0.4922\n",
            "Step 15400, Minibatch loss 2.0269, Train acc 0.4688, Best train acc 0.4922\n",
            "Step 15600, Minibatch loss 2.0272, Train acc 0.4375, Best train acc 0.4922\n",
            "Step 15800, Minibatch loss 2.0078, Train acc 0.4766, Best train acc 0.4922\n",
            "Step 16000, Minibatch loss 1.9979, Train acc 0.4688, Best train acc 0.4922\n",
            "Step 16200, Minibatch loss 2.0208, Train acc 0.4609, Best train acc 0.4922\n",
            "Step 16400, Minibatch loss 2.0094, Train acc 0.4844, Best train acc 0.4922\n",
            "Step 16600, Minibatch loss 2.0421, Train acc 0.4375, Best train acc 0.4922\n",
            "Step 16800, Minibatch loss 2.0164, Train acc 0.4688, Best train acc 0.4922\n",
            "Step 17000, Minibatch loss 2.0230, Train acc 0.4375, Best train acc 0.4922\n",
            "Step 17200, Minibatch loss 2.0450, Train acc 0.4453, Best train acc 0.4922\n",
            "Step 17400, Minibatch loss 2.0440, Train acc 0.4141, Best train acc 0.4922\n",
            "Step 17600, Minibatch loss 1.9718, Train acc 0.5078, Best train acc 0.5078\n",
            "Step 17800, Minibatch loss 2.0112, Train acc 0.4688, Best train acc 0.5078\n",
            "Step 18000, Minibatch loss 1.9733, Train acc 0.5078, Best train acc 0.5078\n",
            "Step 18200, Minibatch loss 2.0657, Train acc 0.3984, Best train acc 0.5078\n",
            "Step 18400, Minibatch loss 1.9808, Train acc 0.4922, Best train acc 0.5078\n",
            "Step 18600, Minibatch loss 1.9696, Train acc 0.5078, Best train acc 0.5078\n",
            "Step 18800, Minibatch loss 1.9752, Train acc 0.5078, Best train acc 0.5078\n",
            "Step 19000, Minibatch loss 2.0454, Train acc 0.4141, Best train acc 0.5078\n",
            "Step 19200, Minibatch loss 2.0018, Train acc 0.4844, Best train acc 0.5078\n",
            "Step 19400, Minibatch loss 2.0059, Train acc 0.4609, Best train acc 0.5078\n",
            "Step 19600, Minibatch loss 1.9646, Train acc 0.5312, Best train acc 0.5312\n",
            "Step 19800, Minibatch loss 2.0105, Train acc 0.4531, Best train acc 0.5312\n",
            "Step 20000, Minibatch loss 1.9801, Train acc 0.5078, Best train acc 0.5312\n",
            "Step 20200, Minibatch loss 1.9833, Train acc 0.4844, Best train acc 0.5312\n",
            "Step 20400, Minibatch loss 2.0722, Train acc 0.3906, Best train acc 0.5312\n",
            "Step 20600, Minibatch loss 1.9908, Train acc 0.4766, Best train acc 0.5312\n",
            "Step 20800, Minibatch loss 1.9339, Train acc 0.5547, Best train acc 0.5547\n",
            "Step 21000, Minibatch loss 2.0384, Train acc 0.4219, Best train acc 0.5547\n",
            "Step 21200, Minibatch loss 1.9679, Train acc 0.4922, Best train acc 0.5547\n",
            "Step 21400, Minibatch loss 1.9676, Train acc 0.5000, Best train acc 0.5547\n",
            "Step 21600, Minibatch loss 2.0491, Train acc 0.3984, Best train acc 0.5547\n",
            "Step 21800, Minibatch loss 1.9800, Train acc 0.5156, Best train acc 0.5547\n",
            "Step 22000, Minibatch loss 1.9819, Train acc 0.5156, Best train acc 0.5547\n",
            "Step 22200, Minibatch loss 1.9932, Train acc 0.4922, Best train acc 0.5547\n",
            "Step 22400, Minibatch loss 2.0406, Train acc 0.4297, Best train acc 0.5547\n",
            "Step 22600, Minibatch loss 2.0127, Train acc 0.4531, Best train acc 0.5547\n",
            "Step 22800, Minibatch loss 2.0035, Train acc 0.4766, Best train acc 0.5547\n",
            "Step 23000, Minibatch loss 2.0095, Train acc 0.4609, Best train acc 0.5547\n",
            "Step 23200, Minibatch loss 1.9994, Train acc 0.4688, Best train acc 0.5547\n",
            "Step 23400, Minibatch loss 1.9754, Train acc 0.5156, Best train acc 0.5547\n",
            "Step 23600, Minibatch loss 2.0151, Train acc 0.4609, Best train acc 0.5547\n",
            "Step 23800, Minibatch loss 2.0472, Train acc 0.4375, Best train acc 0.5547\n",
            "Step 24000, Minibatch loss 1.8669, Train acc 0.6172, Best train acc 0.6172\n",
            "Step 24200, Minibatch loss 2.0260, Train acc 0.4531, Best train acc 0.6172\n",
            "Step 24400, Minibatch loss 1.9375, Train acc 0.5312, Best train acc 0.6172\n",
            "Step 24600, Minibatch loss 1.9992, Train acc 0.4766, Best train acc 0.6172\n",
            "Step 24800, Minibatch loss 1.9765, Train acc 0.4922, Best train acc 0.6172\n",
            "Step 25000, Minibatch loss 2.0141, Train acc 0.4453, Best train acc 0.6172\n",
            "Step 25200, Minibatch loss 1.9910, Train acc 0.4688, Best train acc 0.6172\n",
            "Step 25400, Minibatch loss 1.9406, Train acc 0.5312, Best train acc 0.6172\n",
            "Step 25600, Minibatch loss 1.9442, Train acc 0.5312, Best train acc 0.6172\n",
            "Step 25800, Minibatch loss 1.9462, Train acc 0.5391, Best train acc 0.6172\n",
            "Step 26000, Minibatch loss 1.8993, Train acc 0.5859, Best train acc 0.6172\n",
            "Step 26200, Minibatch loss 1.9512, Train acc 0.5234, Best train acc 0.6172\n",
            "Step 26400, Minibatch loss 1.9430, Train acc 0.5312, Best train acc 0.6172\n",
            "Step 26600, Minibatch loss 1.9551, Train acc 0.5312, Best train acc 0.6172\n",
            "Step 26800, Minibatch loss 2.0099, Train acc 0.4453, Best train acc 0.6172\n",
            "Step 27000, Minibatch loss 1.9964, Train acc 0.4766, Best train acc 0.6172\n",
            "Step 27200, Minibatch loss 2.0272, Train acc 0.4219, Best train acc 0.6172\n",
            "Step 27400, Minibatch loss 1.9194, Train acc 0.5703, Best train acc 0.6172\n",
            "Step 27600, Minibatch loss 1.9859, Train acc 0.4688, Best train acc 0.6172\n",
            "Step 27800, Minibatch loss 1.9153, Train acc 0.5469, Best train acc 0.6172\n",
            "Step 28000, Minibatch loss 1.9537, Train acc 0.5156, Best train acc 0.6172\n",
            "Step 28200, Minibatch loss 1.9022, Train acc 0.5781, Best train acc 0.6172\n",
            "Step 28400, Minibatch loss 1.9754, Train acc 0.4922, Best train acc 0.6172\n",
            "Step 28600, Minibatch loss 1.9713, Train acc 0.4844, Best train acc 0.6172\n",
            "Step 28800, Minibatch loss 1.9457, Train acc 0.5156, Best train acc 0.6172\n",
            "Step 29000, Minibatch loss 2.0377, Train acc 0.4297, Best train acc 0.6172\n",
            "Step 29200, Minibatch loss 1.9790, Train acc 0.5078, Best train acc 0.6172\n",
            "Step 29400, Minibatch loss 1.9448, Train acc 0.5312, Best train acc 0.6172\n",
            "Step 29600, Minibatch loss 1.9805, Train acc 0.4766, Best train acc 0.6172\n",
            "Step 29800, Minibatch loss 1.9679, Train acc 0.5000, Best train acc 0.6172\n",
            "Step 30000, Minibatch loss 2.0545, Train acc 0.3984, Best train acc 0.6172\n",
            "Step 30200, Minibatch loss 1.9515, Train acc 0.5234, Best train acc 0.6172\n",
            "Step 30400, Minibatch loss 1.9530, Train acc 0.5234, Best train acc 0.6172\n",
            "Step 30600, Minibatch loss 1.9709, Train acc 0.4844, Best train acc 0.6172\n",
            "Step 30800, Minibatch loss 1.9303, Train acc 0.5312, Best train acc 0.6172\n",
            "Step 31000, Minibatch loss 1.9875, Train acc 0.4766, Best train acc 0.6172\n",
            "Step 31200, Minibatch loss 1.9602, Train acc 0.4922, Best train acc 0.6172\n",
            "Step 31400, Minibatch loss 1.8885, Train acc 0.5938, Best train acc 0.6172\n",
            "Step 31600, Minibatch loss 1.9228, Train acc 0.5391, Best train acc 0.6172\n",
            "Step 31800, Minibatch loss 1.9592, Train acc 0.5000, Best train acc 0.6172\n",
            "Step 32000, Minibatch loss 1.9541, Train acc 0.5078, Best train acc 0.6172\n",
            "Step 32200, Minibatch loss 1.9759, Train acc 0.4844, Best train acc 0.6172\n",
            "Step 32400, Minibatch loss 1.9077, Train acc 0.5547, Best train acc 0.6172\n",
            "Step 32600, Minibatch loss 1.9522, Train acc 0.5234, Best train acc 0.6172\n",
            "Step 32800, Minibatch loss 1.9681, Train acc 0.5078, Best train acc 0.6172\n",
            "Step 33000, Minibatch loss 1.9080, Train acc 0.5469, Best train acc 0.6172\n",
            "Step 33200, Minibatch loss 1.8973, Train acc 0.5781, Best train acc 0.6172\n",
            "Step 33400, Minibatch loss 1.9629, Train acc 0.5234, Best train acc 0.6172\n",
            "Step 33600, Minibatch loss 1.9300, Train acc 0.5391, Best train acc 0.6172\n",
            "Step 33800, Minibatch loss 2.0146, Train acc 0.4531, Best train acc 0.6172\n",
            "Step 34000, Minibatch loss 1.9557, Train acc 0.5234, Best train acc 0.6172\n",
            "Step 34200, Minibatch loss 1.9089, Train acc 0.5625, Best train acc 0.6172\n",
            "Step 34400, Minibatch loss 1.8975, Train acc 0.5938, Best train acc 0.6172\n",
            "Step 34600, Minibatch loss 1.9115, Train acc 0.5703, Best train acc 0.6172\n",
            "Step 34800, Minibatch loss 1.9131, Train acc 0.5703, Best train acc 0.6172\n",
            "Step 35000, Minibatch loss 1.9607, Train acc 0.5000, Best train acc 0.6172\n",
            "Step 35200, Minibatch loss 2.0086, Train acc 0.4531, Best train acc 0.6172\n",
            "Step 35400, Minibatch loss 1.9855, Train acc 0.4688, Best train acc 0.6172\n",
            "Step 35600, Minibatch loss 1.9012, Train acc 0.5625, Best train acc 0.6172\n",
            "Step 35800, Minibatch loss 1.9687, Train acc 0.5000, Best train acc 0.6172\n",
            "Step 36000, Minibatch loss 2.0079, Train acc 0.4375, Best train acc 0.6172\n",
            "Step 36200, Minibatch loss 1.8997, Train acc 0.5781, Best train acc 0.6172\n",
            "Step 36400, Minibatch loss 1.9412, Train acc 0.5156, Best train acc 0.6172\n",
            "Step 36600, Minibatch loss 1.9092, Train acc 0.5547, Best train acc 0.6172\n",
            "Step 36800, Minibatch loss 1.9156, Train acc 0.5391, Best train acc 0.6172\n",
            "Step 37000, Minibatch loss 1.9233, Train acc 0.5391, Best train acc 0.6172\n",
            "Step 37200, Minibatch loss 1.9927, Train acc 0.4766, Best train acc 0.6172\n",
            "Step 37400, Minibatch loss 1.8977, Train acc 0.5703, Best train acc 0.6172\n",
            "Step 37600, Minibatch loss 1.9081, Train acc 0.5547, Best train acc 0.6172\n",
            "Step 37800, Minibatch loss 2.0381, Train acc 0.4219, Best train acc 0.6172\n",
            "Step 38000, Minibatch loss 1.8985, Train acc 0.5781, Best train acc 0.6172\n",
            "Step 38200, Minibatch loss 1.9400, Train acc 0.5469, Best train acc 0.6172\n",
            "Step 38400, Minibatch loss 1.9400, Train acc 0.5312, Best train acc 0.6172\n",
            "Step 38600, Minibatch loss 1.9378, Train acc 0.5156, Best train acc 0.6172\n",
            "Step 38800, Minibatch loss 2.0275, Train acc 0.4219, Best train acc 0.6172\n",
            "Step 39000, Minibatch loss 1.9621, Train acc 0.5156, Best train acc 0.6172\n",
            "Step 39200, Minibatch loss 1.9832, Train acc 0.4844, Best train acc 0.6172\n",
            "Step 39400, Minibatch loss 1.9707, Train acc 0.4922, Best train acc 0.6172\n",
            "Step 39600, Minibatch loss 1.9661, Train acc 0.4922, Best train acc 0.6172\n",
            "Step 39800, Minibatch loss 1.9163, Train acc 0.5547, Best train acc 0.6172\n",
            "Step 40000, Minibatch loss 2.0366, Train acc 0.4297, Best train acc 0.6172\n",
            "Step 40200, Minibatch loss 1.9399, Train acc 0.5156, Best train acc 0.6172\n",
            "Step 40400, Minibatch loss 1.9999, Train acc 0.4688, Best train acc 0.6172\n",
            "Step 40600, Minibatch loss 1.9106, Train acc 0.5703, Best train acc 0.6172\n",
            "Step 40800, Minibatch loss 1.9292, Train acc 0.5469, Best train acc 0.6172\n",
            "Step 41000, Minibatch loss 1.9125, Train acc 0.5469, Best train acc 0.6172\n",
            "Step 41200, Minibatch loss 1.8706, Train acc 0.5703, Best train acc 0.6172\n",
            "Step 41400, Minibatch loss 1.8891, Train acc 0.5781, Best train acc 0.6172\n",
            "Step 41600, Minibatch loss 1.9219, Train acc 0.5234, Best train acc 0.6172\n",
            "Step 41800, Minibatch loss 1.9346, Train acc 0.5312, Best train acc 0.6172\n",
            "Step 42000, Minibatch loss 1.9653, Train acc 0.5000, Best train acc 0.6172\n",
            "Step 42200, Minibatch loss 1.8931, Train acc 0.5625, Best train acc 0.6172\n",
            "Step 42400, Minibatch loss 1.8812, Train acc 0.5703, Best train acc 0.6172\n",
            "Step 42600, Minibatch loss 1.9217, Train acc 0.5469, Best train acc 0.6172\n",
            "Step 42800, Minibatch loss 1.9534, Train acc 0.4922, Best train acc 0.6172\n",
            "Step 43000, Minibatch loss 1.9267, Train acc 0.5312, Best train acc 0.6172\n",
            "Step 43200, Minibatch loss 1.9912, Train acc 0.4609, Best train acc 0.6172\n",
            "Step 43400, Minibatch loss 1.8285, Train acc 0.6250, Best train acc 0.6250\n",
            "Step 43600, Minibatch loss 1.9655, Train acc 0.5000, Best train acc 0.6250\n",
            "Step 43800, Minibatch loss 1.9908, Train acc 0.4688, Best train acc 0.6250\n",
            "Step 44000, Minibatch loss 1.9795, Train acc 0.4766, Best train acc 0.6250\n",
            "Step 44200, Minibatch loss 1.9584, Train acc 0.5078, Best train acc 0.6250\n",
            "Step 44400, Minibatch loss 1.9530, Train acc 0.5156, Best train acc 0.6250\n",
            "Step 44600, Minibatch loss 1.9536, Train acc 0.5312, Best train acc 0.6250\n",
            "Step 44800, Minibatch loss 1.9082, Train acc 0.5391, Best train acc 0.6250\n",
            "Step 45000, Minibatch loss 1.8489, Train acc 0.6094, Best train acc 0.6250\n",
            "Step 45200, Minibatch loss 1.9287, Train acc 0.5234, Best train acc 0.6250\n",
            "Step 45400, Minibatch loss 1.9665, Train acc 0.4844, Best train acc 0.6250\n",
            "Step 45600, Minibatch loss 1.9005, Train acc 0.5781, Best train acc 0.6250\n",
            "Step 45800, Minibatch loss 1.9099, Train acc 0.5547, Best train acc 0.6250\n",
            "Step 46000, Minibatch loss 1.8634, Train acc 0.6094, Best train acc 0.6250\n",
            "Step 46200, Minibatch loss 2.0119, Train acc 0.4453, Best train acc 0.6250\n",
            "Step 46400, Minibatch loss 1.9466, Train acc 0.5000, Best train acc 0.6250\n",
            "Step 46600, Minibatch loss 1.8961, Train acc 0.5703, Best train acc 0.6250\n",
            "Step 46800, Minibatch loss 1.8611, Train acc 0.6016, Best train acc 0.6250\n",
            "Step 47000, Minibatch loss 1.8755, Train acc 0.6016, Best train acc 0.6250\n",
            "Step 47200, Minibatch loss 1.9191, Train acc 0.5469, Best train acc 0.6250\n",
            "Step 47400, Minibatch loss 1.8539, Train acc 0.6094, Best train acc 0.6250\n",
            "Step 47600, Minibatch loss 1.9738, Train acc 0.4922, Best train acc 0.6250\n",
            "Step 47800, Minibatch loss 1.9733, Train acc 0.4922, Best train acc 0.6250\n",
            "Step 48000, Minibatch loss 1.9465, Train acc 0.5234, Best train acc 0.6250\n",
            "Step 48200, Minibatch loss 1.9382, Train acc 0.5234, Best train acc 0.6250\n",
            "Step 48400, Minibatch loss 1.9591, Train acc 0.5156, Best train acc 0.6250\n",
            "Step 48600, Minibatch loss 1.9365, Train acc 0.5234, Best train acc 0.6250\n",
            "Step 48800, Minibatch loss 1.9389, Train acc 0.5234, Best train acc 0.6250\n",
            "Step 49000, Minibatch loss 1.9373, Train acc 0.5469, Best train acc 0.6250\n",
            "Step 49200, Minibatch loss 1.8732, Train acc 0.5938, Best train acc 0.6250\n",
            "Step 49400, Minibatch loss 1.9723, Train acc 0.4844, Best train acc 0.6250\n",
            "Step 49600, Minibatch loss 2.0337, Train acc 0.4219, Best train acc 0.6250\n",
            "Step 49800, Minibatch loss 1.9260, Train acc 0.5391, Best train acc 0.6250\n",
            "Step 50000, Minibatch loss 1.8032, Train acc 0.6719, Best train acc 0.6719\n",
            "Step 50200, Minibatch loss 1.9243, Train acc 0.5391, Best train acc 0.6719\n",
            "Step 50400, Minibatch loss 1.8549, Train acc 0.6094, Best train acc 0.6719\n",
            "Step 50600, Minibatch loss 1.8915, Train acc 0.5703, Best train acc 0.6719\n",
            "Step 50800, Minibatch loss 1.8536, Train acc 0.6094, Best train acc 0.6719\n",
            "Step 51000, Minibatch loss 1.8811, Train acc 0.5781, Best train acc 0.6719\n",
            "Step 51200, Minibatch loss 1.8793, Train acc 0.6016, Best train acc 0.6719\n",
            "Step 51400, Minibatch loss 1.8737, Train acc 0.6016, Best train acc 0.6719\n",
            "Step 51600, Minibatch loss 1.9321, Train acc 0.5234, Best train acc 0.6719\n",
            "Step 51800, Minibatch loss 1.9598, Train acc 0.5078, Best train acc 0.6719\n",
            "Step 52000, Minibatch loss 1.9625, Train acc 0.4922, Best train acc 0.6719\n",
            "Step 52200, Minibatch loss 1.9163, Train acc 0.5469, Best train acc 0.6719\n",
            "Step 52400, Minibatch loss 1.9418, Train acc 0.5000, Best train acc 0.6719\n",
            "Step 52600, Minibatch loss 1.8997, Train acc 0.5703, Best train acc 0.6719\n",
            "Step 52800, Minibatch loss 1.9615, Train acc 0.5000, Best train acc 0.6719\n",
            "Step 53000, Minibatch loss 1.9292, Train acc 0.5312, Best train acc 0.6719\n",
            "Step 53200, Minibatch loss 1.9223, Train acc 0.5312, Best train acc 0.6719\n",
            "Step 53400, Minibatch loss 1.9313, Train acc 0.5312, Best train acc 0.6719\n",
            "Step 53600, Minibatch loss 1.8828, Train acc 0.5859, Best train acc 0.6719\n",
            "Step 53800, Minibatch loss 1.9346, Train acc 0.5312, Best train acc 0.6719\n",
            "Step 54000, Minibatch loss 1.9600, Train acc 0.5000, Best train acc 0.6719\n",
            "Step 54200, Minibatch loss 1.8905, Train acc 0.5703, Best train acc 0.6719\n",
            "Step 54400, Minibatch loss 1.8658, Train acc 0.6094, Best train acc 0.6719\n",
            "Step 54600, Minibatch loss 1.8952, Train acc 0.5625, Best train acc 0.6719\n",
            "Step 54800, Minibatch loss 1.9367, Train acc 0.5234, Best train acc 0.6719\n",
            "Step 55000, Minibatch loss 1.9722, Train acc 0.4922, Best train acc 0.6719\n",
            "Step 55200, Minibatch loss 1.9425, Train acc 0.5312, Best train acc 0.6719\n",
            "Step 55400, Minibatch loss 1.9104, Train acc 0.5469, Best train acc 0.6719\n",
            "Step 55600, Minibatch loss 1.8528, Train acc 0.6172, Best train acc 0.6719\n",
            "Step 55800, Minibatch loss 1.8951, Train acc 0.5625, Best train acc 0.6719\n",
            "Step 56000, Minibatch loss 1.9248, Train acc 0.5391, Best train acc 0.6719\n",
            "Step 56200, Minibatch loss 1.8751, Train acc 0.5938, Best train acc 0.6719\n",
            "Step 56400, Minibatch loss 1.9058, Train acc 0.5625, Best train acc 0.6719\n",
            "Step 56600, Minibatch loss 1.9610, Train acc 0.5000, Best train acc 0.6719\n",
            "Step 56800, Minibatch loss 1.8829, Train acc 0.5781, Best train acc 0.6719\n",
            "Step 57000, Minibatch loss 1.8672, Train acc 0.6016, Best train acc 0.6719\n",
            "Step 57200, Minibatch loss 1.8982, Train acc 0.5625, Best train acc 0.6719\n",
            "Step 57400, Minibatch loss 1.9833, Train acc 0.4688, Best train acc 0.6719\n",
            "Step 57600, Minibatch loss 1.9429, Train acc 0.5234, Best train acc 0.6719\n",
            "Step 57800, Minibatch loss 1.9817, Train acc 0.4609, Best train acc 0.6719\n",
            "Step 58000, Minibatch loss 1.8918, Train acc 0.5703, Best train acc 0.6719\n",
            "Step 58200, Minibatch loss 1.9004, Train acc 0.5547, Best train acc 0.6719\n",
            "Step 58400, Minibatch loss 1.8425, Train acc 0.6250, Best train acc 0.6719\n",
            "Step 58600, Minibatch loss 1.8990, Train acc 0.5547, Best train acc 0.6719\n",
            "Step 58800, Minibatch loss 1.9090, Train acc 0.5469, Best train acc 0.6719\n",
            "Step 59000, Minibatch loss 1.9484, Train acc 0.5156, Best train acc 0.6719\n",
            "Step 59200, Minibatch loss 1.9271, Train acc 0.5391, Best train acc 0.6719\n",
            "Step 59400, Minibatch loss 1.8268, Train acc 0.6484, Best train acc 0.6719\n",
            "Step 59600, Minibatch loss 1.9490, Train acc 0.5312, Best train acc 0.6719\n",
            "Step 59800, Minibatch loss 1.9697, Train acc 0.4922, Best train acc 0.6719\n",
            "Step 60000, Minibatch loss 1.9067, Train acc 0.5625, Best train acc 0.6719\n",
            "Step 60200, Minibatch loss 1.8886, Train acc 0.5781, Best train acc 0.6719\n",
            "Step 60400, Minibatch loss 1.8393, Train acc 0.6094, Best train acc 0.6719\n",
            "Step 60600, Minibatch loss 1.9428, Train acc 0.5469, Best train acc 0.6719\n",
            "Step 60800, Minibatch loss 1.8621, Train acc 0.6016, Best train acc 0.6719\n",
            "Step 61000, Minibatch loss 1.9219, Train acc 0.5391, Best train acc 0.6719\n",
            "Step 61200, Minibatch loss 1.9746, Train acc 0.4922, Best train acc 0.6719\n",
            "Step 61400, Minibatch loss 1.8932, Train acc 0.5703, Best train acc 0.6719\n",
            "Step 61600, Minibatch loss 1.9187, Train acc 0.5547, Best train acc 0.6719\n",
            "Step 61800, Minibatch loss 1.9378, Train acc 0.5234, Best train acc 0.6719\n",
            "Step 62000, Minibatch loss 1.9978, Train acc 0.4609, Best train acc 0.6719\n",
            "Step 62200, Minibatch loss 1.8191, Train acc 0.6484, Best train acc 0.6719\n",
            "Step 62400, Minibatch loss 1.9687, Train acc 0.4922, Best train acc 0.6719\n",
            "Step 62600, Minibatch loss 1.8749, Train acc 0.5859, Best train acc 0.6719\n",
            "Step 62800, Minibatch loss 1.8896, Train acc 0.5781, Best train acc 0.6719\n",
            "Step 63000, Minibatch loss 1.9529, Train acc 0.5156, Best train acc 0.6719\n",
            "Step 63200, Minibatch loss 1.9001, Train acc 0.5625, Best train acc 0.6719\n",
            "Step 63400, Minibatch loss 1.9470, Train acc 0.5156, Best train acc 0.6719\n",
            "Step 63600, Minibatch loss 1.9459, Train acc 0.5078, Best train acc 0.6719\n",
            "Step 63800, Minibatch loss 1.9303, Train acc 0.5391, Best train acc 0.6719\n",
            "Step 64000, Minibatch loss 1.9336, Train acc 0.5312, Best train acc 0.6719\n",
            "Step 64200, Minibatch loss 1.9228, Train acc 0.5312, Best train acc 0.6719\n",
            "Step 64400, Minibatch loss 1.9533, Train acc 0.5078, Best train acc 0.6719\n",
            "Step 64600, Minibatch loss 1.9225, Train acc 0.5312, Best train acc 0.6719\n",
            "Step 64800, Minibatch loss 1.9068, Train acc 0.5547, Best train acc 0.6719\n",
            "Step 65000, Minibatch loss 1.9004, Train acc 0.5625, Best train acc 0.6719\n",
            "Step 65200, Minibatch loss 1.9058, Train acc 0.5703, Best train acc 0.6719\n",
            "Step 65400, Minibatch loss 1.9302, Train acc 0.5234, Best train acc 0.6719\n",
            "Step 65600, Minibatch loss 1.9442, Train acc 0.5312, Best train acc 0.6719\n",
            "Step 65800, Minibatch loss 1.8604, Train acc 0.6016, Best train acc 0.6719\n",
            "Step 66000, Minibatch loss 1.9013, Train acc 0.5625, Best train acc 0.6719\n",
            "Step 66200, Minibatch loss 1.9398, Train acc 0.5078, Best train acc 0.6719\n",
            "Step 66400, Minibatch loss 1.9119, Train acc 0.5547, Best train acc 0.6719\n",
            "Step 66600, Minibatch loss 1.9713, Train acc 0.5078, Best train acc 0.6719\n",
            "Step 66800, Minibatch loss 1.9473, Train acc 0.5156, Best train acc 0.6719\n",
            "Step 67000, Minibatch loss 1.8970, Train acc 0.5625, Best train acc 0.6719\n",
            "Step 67200, Minibatch loss 1.8901, Train acc 0.5625, Best train acc 0.6719\n",
            "Step 67400, Minibatch loss 1.9628, Train acc 0.4922, Best train acc 0.6719\n",
            "Step 67600, Minibatch loss 1.8707, Train acc 0.5938, Best train acc 0.6719\n",
            "Step 67800, Minibatch loss 1.9219, Train acc 0.5391, Best train acc 0.6719\n",
            "Step 68000, Minibatch loss 1.9201, Train acc 0.5391, Best train acc 0.6719\n",
            "Step 68200, Minibatch loss 1.8836, Train acc 0.5859, Best train acc 0.6719\n",
            "Step 68400, Minibatch loss 1.8475, Train acc 0.6094, Best train acc 0.6719\n",
            "Step 68600, Minibatch loss 1.9122, Train acc 0.5547, Best train acc 0.6719\n",
            "Step 68800, Minibatch loss 1.8821, Train acc 0.5781, Best train acc 0.6719\n",
            "Step 69000, Minibatch loss 1.9028, Train acc 0.5703, Best train acc 0.6719\n",
            "Step 69200, Minibatch loss 1.9562, Train acc 0.5078, Best train acc 0.6719\n",
            "Step 69400, Minibatch loss 1.8982, Train acc 0.5625, Best train acc 0.6719\n",
            "Step 69600, Minibatch loss 1.8623, Train acc 0.6016, Best train acc 0.6719\n",
            "Step 69800, Minibatch loss 1.9419, Train acc 0.5156, Best train acc 0.6719\n",
            "Step 70000, Minibatch loss 1.8747, Train acc 0.5859, Best train acc 0.6719\n",
            "Step 70200, Minibatch loss 1.8845, Train acc 0.5859, Best train acc 0.6719\n",
            "Step 70400, Minibatch loss 1.8487, Train acc 0.6094, Best train acc 0.6719\n",
            "Step 70600, Minibatch loss 1.9481, Train acc 0.5078, Best train acc 0.6719\n",
            "Step 70800, Minibatch loss 1.8551, Train acc 0.6094, Best train acc 0.6719\n",
            "Step 71000, Minibatch loss 1.9063, Train acc 0.5547, Best train acc 0.6719\n",
            "Step 71200, Minibatch loss 1.9256, Train acc 0.5391, Best train acc 0.6719\n",
            "Step 71400, Minibatch loss 1.9324, Train acc 0.5312, Best train acc 0.6719\n",
            "Step 71600, Minibatch loss 1.8838, Train acc 0.5781, Best train acc 0.6719\n",
            "Step 71800, Minibatch loss 1.8382, Train acc 0.6328, Best train acc 0.6719\n",
            "Step 72000, Minibatch loss 1.9282, Train acc 0.5312, Best train acc 0.6719\n",
            "Step 72200, Minibatch loss 1.9091, Train acc 0.5547, Best train acc 0.6719\n",
            "Step 72400, Minibatch loss 1.8612, Train acc 0.6094, Best train acc 0.6719\n",
            "Step 72600, Minibatch loss 1.9243, Train acc 0.5469, Best train acc 0.6719\n",
            "Step 72800, Minibatch loss 1.8702, Train acc 0.5859, Best train acc 0.6719\n",
            "Step 73000, Minibatch loss 1.9317, Train acc 0.5234, Best train acc 0.6719\n",
            "Step 73200, Minibatch loss 1.8554, Train acc 0.6016, Best train acc 0.6719\n",
            "Step 73400, Minibatch loss 1.8840, Train acc 0.5781, Best train acc 0.6719\n",
            "Step 73600, Minibatch loss 1.8856, Train acc 0.5703, Best train acc 0.6719\n",
            "Step 73800, Minibatch loss 1.8749, Train acc 0.5781, Best train acc 0.6719\n",
            "Step 74000, Minibatch loss 1.8476, Train acc 0.6406, Best train acc 0.6719\n",
            "Step 74200, Minibatch loss 1.9521, Train acc 0.5156, Best train acc 0.6719\n",
            "Step 74400, Minibatch loss 1.8898, Train acc 0.5781, Best train acc 0.6719\n",
            "Step 74600, Minibatch loss 1.9177, Train acc 0.5469, Best train acc 0.6719\n",
            "Step 74800, Minibatch loss 1.8811, Train acc 0.5781, Best train acc 0.6719\n",
            "Step 75000, Minibatch loss 1.8673, Train acc 0.5859, Best train acc 0.6719\n",
            "Step 75200, Minibatch loss 1.8680, Train acc 0.6016, Best train acc 0.6719\n",
            "Step 75400, Minibatch loss 1.9398, Train acc 0.5156, Best train acc 0.6719\n",
            "Step 75600, Minibatch loss 1.9417, Train acc 0.5078, Best train acc 0.6719\n",
            "Step 75800, Minibatch loss 1.9682, Train acc 0.4766, Best train acc 0.6719\n",
            "Step 76000, Minibatch loss 1.9535, Train acc 0.5234, Best train acc 0.6719\n",
            "Step 76200, Minibatch loss 1.9668, Train acc 0.4922, Best train acc 0.6719\n",
            "Step 76400, Minibatch loss 1.9100, Train acc 0.5547, Best train acc 0.6719\n",
            "Step 76600, Minibatch loss 1.8498, Train acc 0.6094, Best train acc 0.6719\n",
            "Step 76800, Minibatch loss 1.9005, Train acc 0.5625, Best train acc 0.6719\n",
            "Step 77000, Minibatch loss 1.8323, Train acc 0.6328, Best train acc 0.6719\n",
            "Step 77200, Minibatch loss 1.9215, Train acc 0.5547, Best train acc 0.6719\n",
            "Step 77400, Minibatch loss 1.8964, Train acc 0.5625, Best train acc 0.6719\n",
            "Step 77600, Minibatch loss 1.8625, Train acc 0.6172, Best train acc 0.6719\n",
            "Step 77800, Minibatch loss 1.8529, Train acc 0.6172, Best train acc 0.6719\n",
            "Step 78000, Minibatch loss 1.8714, Train acc 0.6250, Best train acc 0.6719\n",
            "Step 78200, Minibatch loss 1.8654, Train acc 0.6172, Best train acc 0.6719\n",
            "Step 78400, Minibatch loss 1.8671, Train acc 0.6172, Best train acc 0.6719\n",
            "Step 78600, Minibatch loss 1.8641, Train acc 0.6250, Best train acc 0.6719\n",
            "Step 78800, Minibatch loss 1.8917, Train acc 0.5859, Best train acc 0.6719\n",
            "Step 79000, Minibatch loss 1.8338, Train acc 0.6641, Best train acc 0.6719\n",
            "Step 79200, Minibatch loss 1.8686, Train acc 0.6094, Best train acc 0.6719\n",
            "Step 79400, Minibatch loss 1.8221, Train acc 0.6484, Best train acc 0.6719\n",
            "Step 79600, Minibatch loss 1.8222, Train acc 0.6641, Best train acc 0.6719\n",
            "Step 79800, Minibatch loss 1.9408, Train acc 0.5156, Best train acc 0.6719\n",
            "Step 80000, Minibatch loss 1.7978, Train acc 0.6875, Best train acc 0.6875\n",
            "Step 80200, Minibatch loss 1.8383, Train acc 0.6562, Best train acc 0.6875\n",
            "Step 80400, Minibatch loss 1.9090, Train acc 0.5703, Best train acc 0.6875\n",
            "Step 80600, Minibatch loss 1.8089, Train acc 0.6797, Best train acc 0.6875\n",
            "Step 80800, Minibatch loss 1.8658, Train acc 0.6094, Best train acc 0.6875\n",
            "Step 81000, Minibatch loss 1.8407, Train acc 0.6172, Best train acc 0.6875\n",
            "Step 81200, Minibatch loss 1.8495, Train acc 0.6172, Best train acc 0.6875\n",
            "Step 81400, Minibatch loss 1.8671, Train acc 0.5859, Best train acc 0.6875\n",
            "Step 81600, Minibatch loss 1.8281, Train acc 0.6641, Best train acc 0.6875\n",
            "Step 81800, Minibatch loss 1.8267, Train acc 0.6562, Best train acc 0.6875\n",
            "Step 82000, Minibatch loss 1.8474, Train acc 0.6328, Best train acc 0.6875\n",
            "Step 82200, Minibatch loss 1.8425, Train acc 0.6406, Best train acc 0.6875\n",
            "Step 82400, Minibatch loss 1.8463, Train acc 0.6328, Best train acc 0.6875\n",
            "Step 82600, Minibatch loss 1.8206, Train acc 0.6641, Best train acc 0.6875\n",
            "Step 82800, Minibatch loss 1.8709, Train acc 0.6172, Best train acc 0.6875\n",
            "Step 83000, Minibatch loss 1.8239, Train acc 0.6562, Best train acc 0.6875\n",
            "Step 83200, Minibatch loss 1.8112, Train acc 0.6562, Best train acc 0.6875\n",
            "Step 83400, Minibatch loss 1.8164, Train acc 0.6484, Best train acc 0.6875\n",
            "Step 83600, Minibatch loss 1.8660, Train acc 0.6094, Best train acc 0.6875\n",
            "Step 83800, Minibatch loss 1.8831, Train acc 0.5859, Best train acc 0.6875\n",
            "Step 84000, Minibatch loss 1.7631, Train acc 0.7266, Best train acc 0.7266\n",
            "Step 84200, Minibatch loss 1.8055, Train acc 0.6562, Best train acc 0.7266\n",
            "Step 84400, Minibatch loss 1.8495, Train acc 0.6250, Best train acc 0.7266\n",
            "Step 84600, Minibatch loss 1.8512, Train acc 0.6172, Best train acc 0.7266\n",
            "Step 84800, Minibatch loss 1.7624, Train acc 0.7109, Best train acc 0.7266\n",
            "Step 85000, Minibatch loss 1.9021, Train acc 0.5703, Best train acc 0.7266\n",
            "Step 85200, Minibatch loss 1.8227, Train acc 0.6719, Best train acc 0.7266\n",
            "Step 85400, Minibatch loss 1.8868, Train acc 0.5938, Best train acc 0.7266\n",
            "Step 85600, Minibatch loss 1.8942, Train acc 0.5703, Best train acc 0.7266\n",
            "Step 85800, Minibatch loss 1.8451, Train acc 0.6406, Best train acc 0.7266\n",
            "Step 86000, Minibatch loss 1.8351, Train acc 0.6250, Best train acc 0.7266\n",
            "Step 86200, Minibatch loss 1.8315, Train acc 0.6172, Best train acc 0.7266\n",
            "Step 86400, Minibatch loss 1.7573, Train acc 0.7344, Best train acc 0.7344\n",
            "Step 86600, Minibatch loss 1.9160, Train acc 0.5469, Best train acc 0.7344\n",
            "Step 86800, Minibatch loss 1.8372, Train acc 0.6328, Best train acc 0.7344\n",
            "Step 87000, Minibatch loss 1.8488, Train acc 0.6406, Best train acc 0.7344\n",
            "Step 87200, Minibatch loss 1.8531, Train acc 0.6016, Best train acc 0.7344\n",
            "Step 87400, Minibatch loss 1.9044, Train acc 0.5625, Best train acc 0.7344\n",
            "Step 87600, Minibatch loss 1.8513, Train acc 0.6094, Best train acc 0.7344\n",
            "Step 87800, Minibatch loss 1.8518, Train acc 0.6172, Best train acc 0.7344\n",
            "Step 88000, Minibatch loss 1.7911, Train acc 0.6875, Best train acc 0.7344\n",
            "Step 88200, Minibatch loss 1.7772, Train acc 0.6953, Best train acc 0.7344\n",
            "Step 88400, Minibatch loss 1.8338, Train acc 0.6406, Best train acc 0.7344\n",
            "Step 88600, Minibatch loss 1.8358, Train acc 0.6484, Best train acc 0.7344\n",
            "Step 88800, Minibatch loss 1.8466, Train acc 0.6094, Best train acc 0.7344\n",
            "Step 89000, Minibatch loss 1.8545, Train acc 0.6094, Best train acc 0.7344\n",
            "Step 89200, Minibatch loss 1.8474, Train acc 0.6250, Best train acc 0.7344\n",
            "Step 89400, Minibatch loss 1.8055, Train acc 0.6719, Best train acc 0.7344\n",
            "Step 89600, Minibatch loss 1.7961, Train acc 0.6797, Best train acc 0.7344\n",
            "Step 89800, Minibatch loss 1.8932, Train acc 0.5625, Best train acc 0.7344\n",
            "Step 90000, Minibatch loss 1.8366, Train acc 0.6250, Best train acc 0.7344\n",
            "Step 90200, Minibatch loss 1.7908, Train acc 0.6797, Best train acc 0.7344\n",
            "Step 90400, Minibatch loss 1.7845, Train acc 0.6875, Best train acc 0.7344\n",
            "Step 90600, Minibatch loss 1.8146, Train acc 0.6641, Best train acc 0.7344\n",
            "Step 90800, Minibatch loss 1.8390, Train acc 0.6406, Best train acc 0.7344\n",
            "Step 91000, Minibatch loss 1.8025, Train acc 0.6406, Best train acc 0.7344\n",
            "Step 91200, Minibatch loss 1.7917, Train acc 0.6797, Best train acc 0.7344\n",
            "Step 91400, Minibatch loss 1.8056, Train acc 0.6719, Best train acc 0.7344\n",
            "Step 91600, Minibatch loss 1.7709, Train acc 0.6953, Best train acc 0.7344\n",
            "Step 91800, Minibatch loss 1.7699, Train acc 0.7109, Best train acc 0.7344\n",
            "Step 92000, Minibatch loss 1.9220, Train acc 0.5391, Best train acc 0.7344\n",
            "Step 92200, Minibatch loss 1.8608, Train acc 0.5938, Best train acc 0.7344\n",
            "Step 92400, Minibatch loss 1.8680, Train acc 0.6172, Best train acc 0.7344\n",
            "Step 92600, Minibatch loss 1.7802, Train acc 0.6953, Best train acc 0.7344\n",
            "Step 92800, Minibatch loss 1.8658, Train acc 0.5938, Best train acc 0.7344\n",
            "Step 93000, Minibatch loss 1.8661, Train acc 0.5859, Best train acc 0.7344\n",
            "Step 93200, Minibatch loss 1.8170, Train acc 0.6562, Best train acc 0.7344\n",
            "Step 93400, Minibatch loss 1.8045, Train acc 0.6562, Best train acc 0.7344\n",
            "Step 93600, Minibatch loss 1.8190, Train acc 0.6484, Best train acc 0.7344\n",
            "Step 93800, Minibatch loss 1.8245, Train acc 0.6484, Best train acc 0.7344\n",
            "Step 94000, Minibatch loss 1.8834, Train acc 0.5703, Best train acc 0.7344\n",
            "Step 94200, Minibatch loss 1.8651, Train acc 0.6094, Best train acc 0.7344\n",
            "Step 94400, Minibatch loss 1.8033, Train acc 0.6719, Best train acc 0.7344\n",
            "Step 94600, Minibatch loss 1.8273, Train acc 0.6406, Best train acc 0.7344\n",
            "Step 94800, Minibatch loss 1.8981, Train acc 0.5703, Best train acc 0.7344\n",
            "Step 95000, Minibatch loss 1.8339, Train acc 0.6172, Best train acc 0.7344\n",
            "Step 95200, Minibatch loss 1.9594, Train acc 0.5000, Best train acc 0.7344\n",
            "Step 95400, Minibatch loss 1.8090, Train acc 0.6484, Best train acc 0.7344\n",
            "Step 95600, Minibatch loss 1.8514, Train acc 0.6094, Best train acc 0.7344\n",
            "Step 95800, Minibatch loss 1.7054, Train acc 0.7656, Best train acc 0.7656\n",
            "Step 96000, Minibatch loss 1.8790, Train acc 0.5859, Best train acc 0.7656\n",
            "Step 96200, Minibatch loss 1.8752, Train acc 0.5703, Best train acc 0.7656\n",
            "Step 96400, Minibatch loss 1.8533, Train acc 0.6172, Best train acc 0.7656\n",
            "Step 96600, Minibatch loss 1.9040, Train acc 0.5703, Best train acc 0.7656\n",
            "Step 96800, Minibatch loss 1.7908, Train acc 0.6797, Best train acc 0.7656\n",
            "Step 97000, Minibatch loss 1.7867, Train acc 0.6719, Best train acc 0.7656\n",
            "Step 97200, Minibatch loss 1.8075, Train acc 0.6641, Best train acc 0.7656\n",
            "Step 97400, Minibatch loss 1.8199, Train acc 0.6484, Best train acc 0.7656\n",
            "Step 97600, Minibatch loss 1.7729, Train acc 0.7031, Best train acc 0.7656\n",
            "Step 97800, Minibatch loss 1.7849, Train acc 0.6875, Best train acc 0.7656\n",
            "Step 98000, Minibatch loss 1.8336, Train acc 0.6250, Best train acc 0.7656\n",
            "Step 98200, Minibatch loss 1.8108, Train acc 0.6562, Best train acc 0.7656\n",
            "Step 98400, Minibatch loss 1.7818, Train acc 0.6875, Best train acc 0.7656\n",
            "Step 98600, Minibatch loss 1.8118, Train acc 0.6641, Best train acc 0.7656\n",
            "Step 98800, Minibatch loss 1.8783, Train acc 0.5938, Best train acc 0.7656\n",
            "Step 99000, Minibatch loss 1.7651, Train acc 0.7031, Best train acc 0.7656\n",
            "Step 99200, Minibatch loss 1.8385, Train acc 0.6172, Best train acc 0.7656\n",
            "Step 99400, Minibatch loss 1.8668, Train acc 0.5859, Best train acc 0.7656\n",
            "Step 99600, Minibatch loss 1.7316, Train acc 0.7422, Best train acc 0.7656\n",
            "Step 99800, Minibatch loss 1.7744, Train acc 0.6875, Best train acc 0.7656\n",
            "Step 100000, Minibatch loss 1.7914, Train acc 0.6797, Best train acc 0.7656\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFnCAYAAACPasF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwzB4ExERZZj/D8lpmKZLCnQfAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Model took 154.3179 mins (2.5720 hrs) to finish training with best train accuracy of 76.5625%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cdXKqJd6HsXp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 6. Test"
      ]
    },
    {
      "metadata": {
        "id": "Yk68rlOSNXi5",
        "colab_type": "code",
        "outputId": "8f2411fe-67f7-4266-b740-c9c631c87b01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "cell_type": "code",
      "source": [
        "# Accuracy\n",
        "test_len = 128\n",
        "x_test_images = mnist.test.images[:test_len].reshape((-1, params['time_steps'], params['n_input']))\n",
        "x_test_label = mnist.test.labels[:test_len]\n",
        "print(\"Testing Accuracy: {:.2f}%\".format(sess.run(accuracy, feed_dict={x: x_test_images, y: x_test_label})*100))\n",
        "\n",
        "# Show image prediction test\n",
        "x_test_images = mnist.test.images[:4].reshape((-1, params['time_steps'], params['n_input']))\n",
        "x_test_label = mnist.test.labels[:4]\n",
        "\n",
        "x_test_prediction = sess.run(pred, feed_dict={x: x_test_images})\n",
        "x_test_target = sess.run(tar, feed_dict={y: x_test_label})\n",
        "\n",
        "fig, axes = plt.subplots(nrows=2, ncols=2)\n",
        "# axes = axes.ravel()\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "  ax.imshow(x_test_images[i]) \n",
        "  ax.set_title('Target: {} - Prediction: {}'.format(x_test_target[i], x_test_prediction[i]))\n",
        "  ax.set_xticks([])\n",
        "  ax.set_yticks([])\n",
        "plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing Accuracy: 69.53%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAakAAAGACAYAAAAXj52lAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3X18zefBx/FvQmIxaVYP6QNVs4oW\n9bR4aoYkXk2OUqzqocVNo3vV7NVnN6uH0dZ0s7UeOvdrMV5YsVFuXbtaMQ2dx4ix9m67DhWUkJJE\nRMjjdf9hzqTnOuREElfk8/4r+frl97vOaX7ne66Tq79fkDHGCAAABwXf6AEAAOAPJQUAcBYlBQBw\nFiUFAHAWJQUAcBYlBQBwVt3qOtD06dO1e/duSdKxY8cUGRmpevXqSZLWrFmjBg0aVOnxDx06pOzs\nbEVHR191u+eff16ff/659/u8vDxFR0dr7ty55T7WkSNHlJiYqBYtWkiSSktLFRkZqalTp+ree++t\n0Pgv++lPf6rmzZvrqaeeUr9+/bRy5Uo1bNjQ7/arV6/W0KFDVVJSUq7tK2L9+vWaP39+mezw4cPa\nv3+/wsLCKvVYcFNNOb+Lioo0a9Ys7dy5U8YY9ejRQ9OmTVOdOnXKfazi4mK1bdtWd999t4KDg2WM\nUXh4uCZMmKDu3btf1+N48803dfLkSf385z/XqFGjNGXKlKu+Zlw+vyWVa/uK2rx5s+bNm6fCwkLd\neuutmjx5su6///5KP46VuQHi4uLMnj17qvWYCxYsMMnJyQH/XFJSktmyZUtAP5Oenm7atWtXJvvT\nn/5k4uLiTFFRUcBjuNKkSZPMggULyrVtRkaGSUxMvK7jVcS7775rnn322Wo/Ltzg8vmdnJxsnnzy\nSVNQUGAKCgrM0KFDzZo1awI6VlFRkYmKijKZmZneLDU11XTt2tVkZWUFPPYrzZ8/30yePLlc2xYW\nFpouXbpc1/HKIysry3Tu3Nn861//MsYY8+GHH5q4uLgqP+5lznzcd+jQIQ0fPlx9+/ZVQkKC1q9f\nL+nSu5bWrVsrOTlZiYmJkqQtW7aoV69eeuihh/T222+rQ4cOOnnypCRp5cqV8ng8io+P14QJE1RQ\nUKBNmzZp8eLFWrJkiWbPnq2SkhJ5PB5lZWVddUwffvihJKl3797X/fgGDBigvLw8paena8eOHXr8\n8cf19NNPa+LEiZKkjRs36uGHH1afPn305JNPKicnR5KUlZWl0aNHKz4+XuPGjdP58+fLPC9ff/21\nJOm3v/2t+vTpo8TERP3yl7+UJA0fPlxfffWVPB6PCgsLy2y/dOlS9e3bVx6PRz/5yU+8z8WECRP0\nm9/8RmPGjFFsbKzGjh2rixcvSpJmz56t1atXX/VxXrhwQfPnz9eECROu+znDzcOV87tbt2566aWX\nFBoaqtDQUN1///06ePDgdT++Ll266M4779THH3+sI0eOKDY2VjNnztTo0aMlSXv27NEjjzyiBx98\nUMOGDdNXX30l6dL58swzzyguLk6jRo3SqVOnvPvs1auX9u/fL0lau3atEhISlJiYqEmTJqmwsFBj\nxoxRbm6uPB6PTpw4UWb7999/X/3795fH49Ho0aN17NgxSdKcOXM0c+ZMjR8/Xn369NHQoUN1+vRp\nSdKyZcv05ptv+jy2Y8eOqUGDBmrVqpUkqXv37jp+/Lj3tajKVVsdXsH2Tmvs2LFm0aJFxhhjduzY\nYTp27GiKi4u971oWLlxojLn07qF79+5m27ZtxhhjZs2aZVq3bm0yMjLMzp07TUxMjMnMzDSlpaVm\n8uTJ5le/+pUxxpgXX3wx4JnUoEGDTFpaWsCPzzaTKi0tNZ06dTJHjhwx27dvN/fff79JTU01xhhz\n+PBh06lTJ3Pw4EFjjDG/+c1vzHPPPed9fBMnTjTGGHPkyBHTsWNHs2DBgjLv5nbt2mUSExNNXl6e\nKSgoMD/84Q/Nxo0bzfbt270zqSu337Nnj4mNjTVnzpwxxhjzs5/9zEybNs37PPXv39/k5OSYwsJC\n069fP/P++++X+7EvXbrUTJkyJeDnDDePmnJ+FxYWmr59+5r169cH9HO2mZQxxvTv39/s2LHDpKen\nm7Zt25p33nnHGGNMbm6uiY6ONjt37jTGGLNu3TozZMgQY4wxy5YtM6NGjTLFxcXmzJkzpnfv3t6Z\nVM+ePc2+fftMenq66dGjh8nMzDQlJSXmqaeeMkuWLPF5nbm8/dGjR010dLQ5evSoMebS7DEpKckY\nY8wbb7xhYmJizIkTJ0xpaalJSkq65vOWn59vYmJizO7du73jHzp0aEDP2fVwZia1cOFCjRkzRpIU\nHR2t/Px8b8NLUlxcnCTpyy+/lDFGMTExkqSRI0fK/PvKTikpKerXr5+aNGmioKAgDR8+XJs2barQ\neLZv367Q0FB9//vfv45HdYkxRitXrlTz5s111113SZK+/e1vq0uXLpKkjz76SA888IC+973vSZIe\ne+wx/fWvf5UxRnv27FHfvn0lSc2bN7eOZ+vWrYqLi9O3v/1thYaGasWKFYqPj/c7nq1bt8rj8Xj/\nNjVkyBBt377d+++xsbGKiIhQSEiIoqKidOLEiXI9zpKSEi1btkxPPPFEubZH7eHa+W2M0fTp09W8\neXPvDO56pKSkKCcnRx06dJB06W9fDz74oCQpNTVVzZo18/69auDAgTpw4IBOnTqltLQ0JSYmqk6d\nOmrYsKH1U5tt27YpOjpaTZo0UXBwsObNm6eRI0f6Hcv27dvVo0cP72vNkCFDtGvXLpWWlkqSunbt\nqjvuuENBQUFq06aNMjIyrvrYwsLC9Morr2js2LHq2rWrZs2apSlTpgT+JFVQtS2cuJatW7cqOTlZ\n2dnZCgoKkiTvL6ckRURESJJyc3O9X0vSbbfd5v06NzdXKSkp2rp1q/fni4qKKjSeP//5z+rXr5/f\nfx81apS+/vpr1a1bV3/+8599/r2oqEgej8c7jqioKC1YsMD72K58DLm5udq1a5d3e+lSiZ09e1Zn\nz54t80fnK3/usuzsbO8vpKRrLlbIysoqs31ERESZj0bCw8O9XwcHB3t/ua9l7969ioiI8JYtcJlL\n53dRUZF++tOfKi8vT/Pnz1dwsO979RdffFGffvqpJGn58uVq3LixzzYjRozwLpxo1qyZfve736l+\n/fqSpNDQUO/X586d0+HDh8uc32FhYcrOzlZOTo7P+X3mzJkyx8nOzi5zTl5ekOJPVlZWmecwIiJC\nxcXF3j8hXHm84OBglZSUXHV/J0+e1M9+9jOtW7dO99xzj3bu3Kmf/OQn2rhxY7UsjHKipAoLC/Xs\ns89qwYIF6tmzpy5evOh9R/JNDRo0KPNZaGZmpvfryMhIPfroo9f99xBjjLZs2aJx48b53eatt966\n6j5CQkL0wQcflOt4t912m3r27Kk5c+b4/FtERITy8vK832dlZfmUwK233qrs7Gzv91e+ENg0btzY\n+wt7eftGjRqVa6xXk5KSol69el33fnBzce38njx5skpLS7VgwQLVrWt/CXz99devuZ8VK1aoSZMm\n19wuMjJSUVFR1r/n2s7vb7r11lv12Wefeb8/d+6cCgoK/B6vcePGZVYo5+TkKCQkRN/5zneuOVab\nvXv3qkWLFrrnnnskST169FBpaakOHz6sNm3aVGifgXDi4768vDwVFhaqXbt2Msbo97//vUJCQqx/\nmGvZsqUuXLigtLQ0SdKqVau8/9anTx9t2LDB+4K9ceNGLV68WNKl0sjNzS3XeDIzM3Xu3Dk1b978\neh9aufTs2VOpqaneP6bu27dPr732miSpY8eO3o800tPTtW/fPp+fj4+P1+bNm3Xu3DkVFRXpxz/+\nsXbs2KG6desqPz/f551S7969tWHDBuXk5MgYo1WrVik2Nva6H8cXX3zBLAo+XDq/169fr2PHjmn2\n7Nl+C6qydezYUSdOnNAnn3wi6dL/ojJp0iQZY9SxY0dt3rxZpaWlOnPmjD766COfn4+NjVVaWppO\nnDghY4ymTp2qdevWqW7duiopKVF+fn6Z7WNiYrR7924dP35ckvSHP/xBP/jBD6wzxvL47ne/qy++\n+ML7sf/HH3+s/Px8NWvWrEL7C5QTM6mGDRvqiSee0MCBA9WoUSONHz9e8fHx+tGPfqT33nuvzLb1\n6tXT9OnTNXHiRN1yyy1KSkqSJAUFBal9+/YaO3asRowYIWOMGjdurFdeeUXSpRfyiRMn6vjx4/r1\nr3991f9n6NSpU2rUqNFVZyOV6fbbb9fLL7+sH//4xyouLlaDBg28n/mOGzdOL7zwguLj49WqVSvv\n59xXio6O1n/9139pwIABCg0NVWxsrPr27au8vDyFhYUpJiZGa9eu9W7fuXNnPfHEE3r88cdVWlqq\ntm3batKkSdcc5+zZs9WiRQvv/5fxTSdPnizXO0vULi6d36tWrdLRo0f18MMPe7Po6GjNnDmzyh5/\n/fr1NXfuXM2YMUP5+fkKDQ3Vc889p6CgIA0bNkx79+5Vnz591LRpUyUkJOjChQtlfr5p06aaPn26\nRo4cqZCQELVv316jR49WnTp11L59e/Xu3dtb1pe3nzFjhsaNG6fi4mI1a9asXI9v2bJlys3N1dNP\nP10mb9OmjZ577jklJSXJGKN69erp9ddf1y233FI5T9A1BBlTs+8nde7cOUVHR2vfvn3ez4AB3Bw4\nv+HEx32BGjRokDZs2CDp0vQ9KiqKX2DgJsH5jSvVyJlUamqqXn31VRUWFio8PFwzZsxQu3btbvSw\nAFQCzm9cqUaWFACgdqiRH/cBAGoHSgoA4CxKCgDgLEoKAOAsSgoA4CxKCgDgLEoKAOAsSgoA4CxK\nCgDgLEoKAOAsSgoA4CxKCgDgLEoKAOAsSgoA4CxKCgDgLEoKAOAsSgoA4CxKCgDgLEoKAOCsujd6\nAABQ1VasWOGTnT9/3rrt3r17rfnChQsDOua0adOseXx8vDWPjY0NaP+1BTMpAICzKCkAgLMoKQCA\nsygpAICzgowx5kYPAgAqw/jx4615cnJyNY/EvzZt2ljzbdu2+WQRERFVPRznMZMCADiLkgIAOIuS\nAgA4i5ICADiLkgIAOIvVfQBqnKpcxdepUydrPnjwYGt+4MABa75s2bKAjmu77NLYsWMD2sfNiJkU\nAMBZlBQAwFmUFADAWZQUAMBZlBQAwFnc9BCAs44ePWrNFy1aFNB+unTp4pN98MEH1m3r169vzUND\nQ615SUmJNT948KA13759uzU/ffq0Na/tmEkBAJxFSQEAnEVJAQCcRUkBAJxFSQEAnFVjVvft2rXL\nms+bN8+aN23a1JqHhYVZ89GjR/tkDRs2tG7rLwdQufytePN3yVHbKj5J+utf/+qTNWjQoOIDu8LS\npUut+Z49ewLaz8CBAythNDcfZlIAAGdRUgAAZ1FSAABnUVIAAGdRUgAAZ9WYO/O2bt3amvu7K2Zl\niIiIsObdu3evsmNWtRYtWljzl156yZo3b968CkcDVMzZs2etub/r6/lb1VsZevToYc1TU1MD2s+n\nn37qk917770VGtPNhJkUAMBZlBQAwFmUFADAWZQUAMBZlBQAwFk15tp977zzjjXfv3+/NW/btq01\nt62gkaTdu3f7ZH/605+s227YsMGaf/e737Xmhw8ftuaBqlvX9z/XHXfcYd322LFjAe3b36q/SZMm\nBbQfoDr4W3lbld566y1r/o9//COg/SQkJFjz733vewGPqTZgJgUAcBYlBQBwFiUFAHAWJQUAcBYl\nBQBwVo25dt+NcPHiRWuenp5uzf2t7vvyyy8rZTy265L5W93nbyxff/21NV+3bp01526hqG327dtn\nzWNiYqx5QUGBNfd3bn744YfWPCoqqhyjq32YSQEAnEVJAQCcRUkBAJxFSQEAnFVjLot0I3zrW9+y\n5oHeiOy+++6rjOFY2S7nJEmnT5+25t26dbPm/i7VAtQ2O3futOb+Fkj4M27cOGvOAonAMJMCADiL\nkgIAOIuSAgA4i5ICADiLkgIAOIvLItUg58+f98latWpl3TYjI8Oa79q1y5r7W/UH3KySkpKs+apV\nq6y5v8ukPf/889Z81qxZ1tx2eTP4x0wKAOAsSgoA4CxKCgDgLEoKAOAsSgoA4Cyu3VeDLF261Cc7\nefKkddtGjRpZ87vvvrsyhwTUCHl5eT7ZX/7yF+u2/lbx3XbbbdZ88uTJ1pxVfJWDmRQAwFmUFADA\nWZQUAMBZlBQAwFmUFADAWazuc9ChQ4es+QsvvFDuffi7u+jtt99eoTEBNdmQIUN8sszMzID28cwz\nz1jzhg0bVmhMKB9mUgAAZ1FSAABnUVIAAGdRUgAAZ1FSAABnsbrPQe+99541Lyoq8slsq5YkqWXL\nlpU6JqAm2Lt3rzXfsmVLuffxyCOPWPNAVtei8jCTAgA4i5ICADiLkgIAOIuSAgA4i5ICADiL1X03\nkG21niStW7fOmterV88ne+2116zb1qlTp+IDAxx34cIFa/7SSy9Z88LCwnLv+/vf/7415067NwYz\nKQCAsygpAICzKCkAgLMoKQCAsygpAICzWN13Ay1evNia/+1vf7Pmjz/+uE/GNfpQG/32t7+15ps3\nby73PpKSkqw51+hzCzMpAICzKCkAgLMoKQCAsygpAICzgowx5kYP4ma3f/9+a96lSxdrHh4ebs3T\n0tJ8MhZOoDYKCwuz5oFc/ujs2bPWvEGDBhUaE6oGMykAgLMoKQCAsygpAICzKCkAgLMoKQCAs7gs\nUiXydyO2xx57zJqXlJRY8xEjRlhzVvIBlScvL8+aBwdX7Xt3281LJfuNSv29RhQUFAR0TH+vTfPm\nzQtoPzb+brA6efJkax4SEhLQ/plJAQCcRUkBAJxFSQEAnEVJAQCcRUkBAJzF6r4KKC0tteb9+vWz\n5l988YU1v++++6z5yy+/XLGBASi3pk2b3pDjjhs3zprfeeedPtnJkyet2/7P//xPpY6pKvh7fp98\n8smA9sNMCgDgLEoKAOAsSgoA4CxKCgDgLEoKAOAs7sxbAadPn7bmkZGRAe3HdqddSercuXPAYwJq\nE38rxJYsWVLNI3FL3br2Bdv+rq/nz5gxY6x5jx49yr2PmJgYax7oNUiZSQEAnEVJAQCcRUkBAJxF\nSQEAnEVJAQCcxbX7ruLs2bPWvHv37gHtZ/ny5da8U6dOAY8JgLRo0SJr3qtXL2teWFh43cf8xz/+\nYc0r6zp6//3f/+2T3XPPPQHtY8CAAdY80JXHLmEmBQBwFiUFAHAWJQUAcBYlBQBwFiUFAHAW1+67\nirlz51rzF154IaD9pKenW/PmzZsHOiQAqFWYSQEAnEVJAQCcRUkBAJxFSQEAnEVJAQCcxbX7/u3A\ngQM+2YwZM6p/IAAAL2ZSAABnUVIAAGdRUgAAZ1FSAABnsXDi3/72t7/5ZLm5uQHt47777rPmYWFh\nFRoTANR2zKQAAM6ipAAAzqKkAADOoqQAAM6ipAAAzmJ1XwU88MAD1nzTpk3WnNV9AFAxzKQAAM6i\npAAAzqKkAADOoqQAAM6ipAAAzgoyxpgbPQgAAGyYSQEAnEVJAQCcRUkBAJxFSQEAnEVJAQCcRUkB\nAJxFSQEAnEVJAQCcRUkBAJxFSQEAnEVJAQCcRUkBAJxFSQEAnEVJAQCcRUkBAJxFSQEAnEVJAQCc\nRUkBAJxFSQEAnFVtJTV9+nR5PB55PB61bdtWcXFx3u/z8vKq/PiHDh1SWlpaubZNT0/XwIEDNXbs\n2Aodq7i4WK1bt1ZCQoI8Ho8SExP16KOPateuXRXa35XefPNNTZkyRZI0atQo/fOf/7zq9qtXr/Z+\nXZ7tK8oYo4ULF6pt27bav39/lRwD7qop57cxRrNnz1ZiYqI8Ho/mzJkT8LFq4/n92WefadiwYUpM\nTNRjjz2mAwcOVMlxrMwNEBcXZ/bs2VOtx1ywYIFJTk6+5nYHDx40Ho/HTJ061SQlJVXoWEVFRSYq\nKspkZmZ6s9TUVNO1a1eTlZVVoX1eNn/+fDN58uRybVtYWGi6dOlyXccrr8mTJ5tp06aZBx54wOzb\nt69ajgk3uXx+v/POO2bYsGGmoKDAFBQUmMGDB5tNmzYFdKzadn6XlpaahIQE8+GHHxpjjNmwYYMZ\nMGBAlR/3Mmc+7jt06JCGDx+uvn37KiEhQevXr5f0n3ctycnJSkxMlCRt2bJFvXr10kMPPaS3335b\nHTp00MmTJyVJK1eulMfjUXx8vCZMmKCCggJt2rRJixcv1pIlSzR79myVlJTI4/EoKyvLZxyhoaF6\n66231L59+0p9fF26dNGdd96pjz/+WEeOHFFsbKxmzpyp0aNHS5L27NmjRx55RA8++KCGDRumr776\nSpJ04cIFPfPMM4qLi9OoUaN06tQp7z579erlnbWsXbtWCQkJSkxM1KRJk1RYWKgxY8YoNzdXHo9H\nJ06cKLP9+++/r/79+8vj8Wj06NE6duyYJGnOnDmaOXOmxo8frz59+mjo0KE6ffq0JGnZsmV68803\nrY/v0Ucf1SuvvKI6depU6vOGm4Mr5/cHH3ygwYMHKzQ0VKGhoRowYID+8pe/XPfju5nP788//1wX\nLlxQXFycJCkhIUEnT55Uenr6dT9v5VJtdXgF2zutsWPHmkWLFhljjNmxY4fp2LGjKS4u9r5rWbhw\noTHm0ruH7t27m23bthljjJk1a5Zp3bq1ycjIMDt37jQxMTEmMzPTlJaWmsmTJ5tf/epXxhhjXnzx\nxXK907ps9erVlTqTMsaY/v37mx07dpj09HTTtm1b88477xhjjMnNzTXR0dFm586dxhhj1q1bZ4YM\nGWKMMWbZsmVm1KhRpri42Jw5c8b07t3b+06rZ8+eZt++fSY9Pd306NHDZGZmmpKSEvPUU0+ZJUuW\nmPT0dNOuXTvv8S9vf/ToURMdHW2OHj1qjDEmOTnZ+1jfeOMNExMTY06cOGFKS0tNUlJSQM/b5WOg\n9nL5/PZ4PN7zzBhjUlJSzA9/+MOAHl9tO7/ff/99M2LEiDLZI488YjZv3hzQ81ZRzsykFi5cqDFj\nxkiSoqOjlZ+f7214Sd4W//LLL2WMUUxMjCRp5MiRMsZIklJSUtSvXz81adJEQUFBGj58uDZt2lS9\nD8SPlJQU5eTkqEOHDpKkoqIiPfjgg5Kk1NRUNWvWTN27d5ckDRw4UAcOHNCpU6eUlpamxMRE1alT\nRw0bNlTv3r199r1t2zZFR0erSZMmCg4O1rx58zRy5Ei/Y9m+fbt69Oihu+66S5I0ZMgQ7dq1S6Wl\npZKkrl276o477lBQUJDatGmjjIyMSn0uUPu4cn5fvHhR9erV835fr1495efnX89D847tZj2/L1y4\nUOY5k6RvfetbunDhQjmfnetTt1qOUg5bt25VcnKysrOzFRQUJEneX05JioiIkCTl5uZ6v5ak2267\nzft1bm6uUlJStHXrVu/PFxUVVcl4X3zxRX366aeSpOXLl6tx48Y+24wYMULBwcEyxqhZs2b63e9+\np/r160u69LHi5a/PnTunw4cPy+PxeH82LCxM2dnZysnJUYMGDbx5RESEzpw5U+Y42dnZCg8P937/\nzV+ob8rKyirzHEZERKi4uFg5OTmSVOZ4wcHBKikpufqTAVyDK+d3WFiYCgoKvN9fvHjRex5eifP7\nP775nEmXisv2vFUFJ0qqsLBQzz77rBYsWKCePXvq4sWL3nck39SgQQOdP3/e+31mZqb368jISD36\n6KOaMGFClY/59ddfv+Y2K1asUJMmTa65XWRkpKKiosqs1LksIiKizOoo2+fst956qz777DPv9+fO\nnfP5pbpS48aN9fnnn3u/z8nJUUhIiL7zne9cc6xAoFw6v1u2bKmjR496ZzVHjhzRPffc47Md5/d/\ntGzZUkeOHPF+X1paqmPHjlmft6rgxMd9eXl5KiwsVLt27WSM0e9//3uFhISU+WW9rGXLlrpw4YJ3\nuemqVau8/9anTx9t2LBB2dnZkqSNGzdq8eLFkqSQkBDl5uZWw6MJXMeOHXXixAl98sknki6dOJMm\nTZIxRh07dtTmzZtVWlqqM2fO6KOPPvL5+djYWKWlpenEiRMyxmjq1Klat26d6tatq5KSEp+PM2Ji\nYrR7924dP35ckvSHP/xBP/jBDxQc7MSvA24yLp3fffv21R//+EddvHhReXl5Wr16tfr161cZD9Ov\nmn5+33vvvWrQoIF3scvatWvVokUL78eJVc2JmVTDhg31xBNPaODAgWrUqJHGjx+v+Ph4/ehHP9J7\n771XZtt69epp+vTpmjhxom655RYlJSVJkoKCgtS+fXuNHTtWI0aMkDFGjRs31iuvvCJJio+P18SJ\nE3X8+HH9+te/Vr9+/bRy5Uo1bNiwzP6XL1+u5cuXKy8vT+fPn5fH41GnTp302muvVdnjr1+/vubO\nnasZM2YoPz9foaGheu655xQUFKRhw4Zp79696tOnj5o2baqEhASfz4KbNm2q6dOna+TIkQoJCVH7\n9u01evRo1alTR+3bt1fv3r29J/Pl7WfMmKFx48apuLhYzZo108yZM685zmXLlik3N1dPP/20z79d\n/ijjzJkzeuGFFxQaGqrXX39dbdu2vc5nBzWdS+f3Qw89pE8//VQPP/ywgoODNWDAAOvfgSrTzXB+\nz5kzR9OmTdPcuXPVuHFjzZ49+/qfmHIKMld+MFwDnTt3TtHR0dq3b1+1fUYKoHpwfqNGfr4zaNAg\nbdiwQZK0fv16RUVF8QsM3CQ4v3GlGjmTSk1N1auvvqrCwkKFh4drxowZateu3Y0eFoBKwPmNK9XI\nkgIA1A418uM+AEDtQEkBAJxFSQEAnEVJAQCcRUkBAJxFSQEAnEVJAQCcRUkBAJxFSQEAnEVJAQCc\nRUkBAJxFSQEAnEVJAQCcRUkBAJxFSQEAnEVJAQCcRUkBAJxFSQEAnEVJAQCcRUkBAJxFSQEAnEVJ\nAQCcRUkBAJxFSQEAnFX3Rg8Avk6fPm3NIyMjfbK3337buu3gwYMrdUxAbVFYWGjNZ86cac1//vOf\nW/PY2Fhr/r//+7/WPCIi4tqDq4WYSQEAnEVJAQCcRUkBAJxFSQEAnEVJAQCcxeo+B33xxRfWPDjY\n9z1Fs2bNqno4QK1y7tw5a/5TLW+jAAAHBUlEQVTaa69Zc9t5KUlbtmyx5ikpKdZ80KBB1x5cLcRM\nCgDgLEoKAOAsSgoA4CxKCgDgLEoKAOAsVvc5aPfu3dY8PDzcJ+vWrVtVDwe4KeXn51vzUaNGVfNI\ncDXMpAAAzqKkAADOoqQAAM6ipAAAzqKkAADOYnXfDZSRkWHNp0+fbs2ff/75qhwOcNNas2aNT/bH\nP/7Ruu2mTZuqdCwbN2605iUlJT5Z+/btrdu2atWqUsfkMmZSAABnUVIAAGdRUgAAZ1FSAABnUVIA\nAGcFGWPMjR5EbbVr1y5r/sADD1jzf/7znz5ZVFRUpY4JuBnVqVPHJ/N3R93KUlpaas0DOa6/VXwb\nNmyw5nfddVe5911TMJMCADiLkgIAOIuSAgA4i5ICADiLkgIAOIvVfTdQnz59rPmxY8es+f/93//5\nZKGhoZU6JqAmGzlypDVfsWKFT1bVq/siIyOt+S233GLNDx48eN3HtF3/r6ZjJgUAcBYlBQBwFiUF\nAHAWJQUAcBYlBQBwFnfmrQY5OTnWPCUlxZr7uxsnK/mAS/71r39Z871791pz20q+ylrdN3XqVGv+\n8MMPW/Pw8HBrbrsj8LPPPhvQWN59911rPmDAgID24xJmUgAAZ1FSAABnUVIAAGdRUgAAZ7Fwohr8\n/e9/D2j7m/HGZUBF+Ft0FB8fb81PnTp13cf0d6PBpKQka+5vcUNISEhAx7VdRukXv/iFdduMjAxr\n7u+yUAsXLrTmQ4YMsea2m0TeKMykAADOoqQAAM6ipAAAzqKkAADOoqQAAM7ipofV4Je//KU1f+ml\nl6x5WlqaNe/cuXOljQmoCc6cOWPNb7/99oD2U1pa6pMNHjzYuu3SpUutef369QM6ZmVYu3atNR8+\nfLg1tz1Oyf8loPythmzYsGE5Rlc9mEkBAJxFSQEAnEVJAQCcRUkBAJxFSQEAnMXqvkr05ZdfWvNu\n3bpZ8zZt2ljzzZs3W/O6dbnUImqXylrdFxsb65OtWbPGum1ERERA+65KZ8+eteb+rrnn77WD1X0A\nAFQBSgoA4CxKCgDgLEoKAOAsSgoA4CyWi1UifytrTp8+bc07dOhgzVnFB1ydv2vU+bNp06YqGknV\n8rf4uqSkxJoH+ry8/PLL1nzevHkB7acqMZMCADiLkgIAOIuSAgA4i5ICADiLkgIAOItlZJXI3x11\ng4KCrPnIkSOrcjhAjbdo0SJr7u9adDcbfyuGP/roI2vu73nxl0+fPr1iA6tGteO/NACgRqKkAADO\noqQAAM6ipAAAzqKkAADO4s68FZCXl2fNW7dubc0jIyOt+b59+yptTMDNqH379tb8888/D2g/RUVF\nlTGcSpGfn2/Nv/rqK58sPj7euq2/O+r6u3Zf06ZNrfknn3xizV26OzEzKQCAsygpAICzKCkAgLMo\nKQCAsygpAICzuHZfBaxZs8aaZ2RkWPPHHnusKocDoAZ54403rLm/u+QGIioqypq/++671tylVXz+\nMJMCADiLkgIAOIuSAgA4i5ICADiLhRMVcOjQoYC2b9SoURWNBICr/N3UdO/evVV2zC5duljzVq1a\nVdkxqxozKQCAsygpAICzKCkAgLMoKQCAsygpAICzuOlhBbRo0cKaHz161Jp/9tln1vzee++trCEB\nN6X777/fmvs7p/z5+9//Xu5tBw4caM2PHTsW0DH93YAwOLjq5gYlJSVVtu8bhZkUAMBZlBQAwFmU\nFADAWZQUAMBZlBQAwFlcu+8qDhw4YM2PHz9ezSMBaqcpU6ZY81GjRgW0n86dO/tkga6yq6xVeZWx\nn6lTp1bCSGoGZlIAAGdRUgAAZ1FSAABnUVIAAGdRUgAAZ7G67yrWrl1rzf1dH6tnz57WPCoqqtLG\nBNQmffv2teZ33HGHNc/IyKjK4VQKf2Pv1q2bT5acnGzdNjw8vFLH5DJmUgAAZ1FSAABnUVIAAGdR\nUgAAZ1FSAABnsbrv34qKinyyVatWBbSP0aNHW/OqvBMncDOLiIiw5ps3b7bma9asseYuXetu/vz5\n1nzQoEHVPJKagVdPAICzKCkAgLMoKQCAsygpAICzKCkAgLOCjDHmRg/CBbbr8fXv39+6rb9rb/m7\nzlZISEjFBwbgun388cc+mb9VdsuWLbPmY8aMsebPPPOMNff30nr33Xdbc38rGWs7ZlIAAGdRUgAA\nZ1FSAABnUVIAAGdRUgAAZ7G6DwDgLGZSAABnUVIAAGdRUgAAZ1FSAABnUVIAAGdRUgAAZ1FSAABn\nUVIAAGdRUgAAZ1FSAABnUVIAAGdRUgAAZ1FSAABnUVIAAGdRUgAAZ1FSAABnUVIAAGdRUgAAZ1FS\nAABnUVIAAGdRUgAAZ1FSAABnUVIAAGdRUgAAZ1FSAABnUVIAAGdRUgAAZ1FSAABnUVIAAGf9P9Yq\nw8UurkGjAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "I3LzFz9FjjM4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 7. Summary\n",
        "*In the MNIST task, conventional RNN performs better due to the simplicity of the task. However, in tasks involving NLP, audio or even more complex images, LSTM and GRU perform better. The reason is that RNN isn't able to model data with long-term dependencies as well due to the gradients becoming increasingly small, vanishing gradient problem.*\n",
        "\n",
        "<table align=\"left\">\n",
        "  <tr>\n",
        "    <td><b>Model</b></td><td><b>Steps</b></td><td align=\"center\"><b>Train Acc (%)</b></td><td align=\"center\"><b>Test Acc (%)</b></td><td align=\"center\"><b>Training Time (min)</b></td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td rowspan=\"2\">RNN</td><td>10,000</td><td align=\"center\">75.00</td><td align=\"center\">80.47</td><td align=\"center\">2.2650</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>100,000</td><td align=\"center\">99.22</td><td align=\"center\">96.88</td><td align=\"center\">23.26</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td rowspan=\"2\">LSTM</td><td>10,000</td><td align=\"center\">41.41</td><td align=\"center\">39.84</td><td align=\"center\">16</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>100,000</td><td align=\"center\">84.37</td><td align=\"center\">69.53</td><td align=\"center\">161.65</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td rowspan=\"2\">GRU</td><td>10,000</td><td align=\"center\">25.00</td><td align=\"center\">22.66</td><td align=\"center\">12</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>100,000</td><td align=\"center\">64</td><td align=\"center\">55.47</td><td align=\"center\">121.46</td>\n",
        "  </tr>\n",
        "</table>"
      ]
    }
  ]
}